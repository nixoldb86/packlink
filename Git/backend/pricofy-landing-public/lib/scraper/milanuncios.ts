// Scraper para Milanuncios usando extracci√≥n de JSON desde HTML
import { ScrapingInputs, AnuncioRaw, PlataformaScraper } from './types'
import { writeFile, mkdir } from 'fs/promises'
import { join } from 'path'
import { existsSync } from 'fs'

export class MilanunciosScraper implements PlataformaScraper {
  nombre = 'milanuncios'

  /**
   * Mapea los estados de Milanuncios a los estados internos del sistema
   */
  private mapearEstadoMilanuncios(estadoMilanuncios: string | null | undefined): string | null {
    if (!estadoMilanuncios) return null

    const estadoNormalizado = estadoMilanuncios.trim()
    
    const mapeoEstados: Record<string, string> = {
      'sin estrenar': 'Nuevo',
      'pr√°cticamente nuevo': 'Como nuevo',
      'practicamente nuevo': 'Como nuevo', // Sin tilde
      'en buen estado': 'Buen estado',
      'aceptable': 'Usado',
      'mejorable': 'Necesita reparaci√≥n',
    }

    // Buscar coincidencia exacta (case-insensitive)
    const estadoLower = estadoNormalizado.toLowerCase()
    if (mapeoEstados[estadoLower]) {
      return mapeoEstados[estadoLower]
    }

    // Si no hay mapeo, devolver el estado original
    return estadoNormalizado
  }

  /**
   * Genera headers aleatorios para simular diferentes navegadores y sesiones
   * Esto ayuda a evitar la detecci√≥n de bots
   */
  private generarHeadersAleatorios(): Record<string, string> {
    // User-Agents de diferentes versiones de Chrome en m√∫ltiples sistemas operativos
    const userAgents = [
      // macOS - Chrome 141-138
      'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36',
      'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
      'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36',
      'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',
      'Mozilla/5.0 (Macintosh; Intel Mac OS X 13_6_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36',
      'Mozilla/5.0 (Macintosh; Intel Mac OS X 13_5_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
      // Windows - Chrome 141-138
      'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36',
      'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
      'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36',
      'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',
      'Mozilla/5.0 (Windows NT 11.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36',
      'Mozilla/5.0 (Windows NT 11.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
      // Linux - Chrome 141-138
      'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36',
      'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
      'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36',
      'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',
      'Mozilla/5.0 (X11; Ubuntu; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36',
      // macOS - Safari (algunas variaciones)
      'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15',
      'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15',
      // Windows - Edge (algunas variaciones)
      'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36 Edg/141.0.0.0',
      'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36 Edg/140.0.0.0',
    ]
    
    // Versiones de Chrome para sec-ch-ua (muchas m√°s opciones)
    const chromeVersions = [
      { major: '141', minor: '0', brand: 'Google Chrome' },
      { major: '140', minor: '0', brand: 'Google Chrome' },
      { major: '139', minor: '0', brand: 'Google Chrome' },
      { major: '138', minor: '0', brand: 'Google Chrome' },
      { major: '141', minor: '0', brand: 'Chromium' },
      { major: '140', minor: '0', brand: 'Chromium' },
      { major: '141', minor: '0', brand: 'Not_A Brand' },
      { major: '140', minor: '0', brand: 'Not_A Brand' },
    ]
    
    // Plataformas con m√°s variaciones
    const platforms = [
      { name: 'macOS', value: '"macOS"' },
      { name: 'Windows', value: '"Windows"' },
      { name: 'Linux', value: '"Linux"' },
      { name: 'Windows', value: '"Windows"' },
      { name: 'macOS', value: '"macOS"' },
    ]
    
    // Variaciones de Accept-Language (muchas m√°s opciones)
    const acceptLanguages = [
      'es-ES,es;q=0.9,en;q=0.8',
      'es-ES,es;q=0.9',
      'es,en-US;q=0.9,en;q=0.8',
      'es-ES,es;q=0.9,en-US;q=0.8,en;q=0.7',
      'es-ES,es;q=0.9,en;q=0.8,fr;q=0.7',
      'es,es-ES;q=0.9,en;q=0.8',
      'es-ES,es;q=0.9,ca;q=0.8,en;q=0.7',
      'es-ES,es;q=0.9,en-US;q=0.8',
      'es,en;q=0.9',
      'es-ES,es;q=0.95,en;q=0.8',
      'es-ES,es;q=0.9,en;q=0.8,pt;q=0.7',
      'es,es-ES;q=0.9,en-US;q=0.8,en;q=0.7',
    ]
    
    // Variaciones de Accept (diferentes √≥rdenes y valores)
    const accepts = [
      'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
      'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
      'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
      'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
      'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
    ]
    
    // Variaciones de Accept-Encoding
    const acceptEncodings = [
      'gzip, deflate, br',
      'gzip, deflate, br, zstd',
      'gzip, deflate',
      'gzip, br',
      'gzip, deflate, br, compress',
    ]
    
    // Variaciones de Cache-Control
    const cacheControls = [
      'max-age=0',
      'no-cache',
      'max-age=0, no-cache',
      'no-cache, no-store',
      'max-age=0, no-cache, no-store',
    ]
    
    // Seleccionar valores aleatorios
    const userAgent = userAgents[Math.floor(Math.random() * userAgents.length)]
    const chromeVersion = chromeVersions[Math.floor(Math.random() * chromeVersions.length)]
    const platform = platforms[Math.floor(Math.random() * platforms.length)]
    const acceptLanguage = acceptLanguages[Math.floor(Math.random() * acceptLanguages.length)]
    const accept = accepts[Math.floor(Math.random() * accepts.length)]
    const acceptEncoding = acceptEncodings[Math.floor(Math.random() * acceptEncodings.length)]
    const cacheControl = cacheControls[Math.floor(Math.random() * cacheControls.length)]
    
    // Generar sec-ch-ua con variaciones (a veces incluir m√°s o menos informaci√≥n)
    const secChUaVariations = [
      `"${chromeVersion.brand}";v="${chromeVersion.major}", "Not?A_Brand";v="8", "Chromium";v="${chromeVersion.major}"`,
      `"${chromeVersion.brand}";v="${chromeVersion.major}", "Not_A Brand";v="8", "Chromium";v="${chromeVersion.major}"`,
      `"${chromeVersion.brand}";v="${chromeVersion.major}.${chromeVersion.minor}", "Not?A_Brand";v="8", "Chromium";v="${chromeVersion.major}"`,
      `"${chromeVersion.brand}";v="${chromeVersion.major}", "Chromium";v="${chromeVersion.major}", "Not?A_Brand";v="8"`,
    ]
    const secChUa = secChUaVariations[Math.floor(Math.random() * secChUaVariations.length)]
    
    // Generar sec-fetch-site con variaciones (a veces same-origin, a veces none)
    const secFetchSites = ['same-origin', 'none', 'same-origin']
    const secFetchSite = secFetchSites[Math.floor(Math.random() * secFetchSites.length)]
    
    // A veces incluir o no algunos headers opcionales
    const headers: Record<string, string> = {
      'Accept': accept,
      'Accept-Language': acceptLanguage,
      'Accept-Encoding': acceptEncoding,
      'Referer': 'https://www.milanuncios.com/',
      'Upgrade-Insecure-Requests': '1',
      'User-Agent': userAgent,
      'sec-ch-ua': secChUa,
      'sec-ch-ua-mobile': '?0',
      'sec-ch-ua-platform': platform.value,
      'sec-fetch-dest': 'document',
      'sec-fetch-mode': 'navigate',
      'sec-fetch-site': secFetchSite,
      'sec-fetch-user': '?1',
      'Cache-Control': cacheControl,
      'Connection': 'keep-alive',
    }
    
    // A veces incluir DNT, a veces no (70% de probabilidad)
    if (Math.random() > 0.3) {
      headers['DNT'] = '1'
    }
    
    // A veces incluir Pragma (30% de probabilidad)
    if (Math.random() > 0.7) {
      headers['Pragma'] = 'no-cache'
    }
    
    return headers
  }

  /**
   * Guarda el HTML recibido en un archivo para debug
   * Incluye el comando curl al principio del archivo
   */
  private async guardarHTML(html: string, producto: string, pagina: number, url: string, curlCommand: string): Promise<void> {
    try {
      // Crear directorio si no existe
      const htmlDir = join(process.cwd(), 'logs', 'HTMLsMilanuncion')
      if (!existsSync(htmlDir)) {
        await mkdir(htmlDir, { recursive: true })
      }

      // Crear nombre de archivo descriptivo
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-').replace('T', '_').split('.')[0]
      const productoSanitizado = producto.replace(/[^a-zA-Z0-9]/g, '_').substring(0, 50)
      const filename = `milanuncios_${productoSanitizado}_pag${pagina}_${timestamp}.html`
      const filepath = join(htmlDir, filename)

      // Preparar contenido: curl al principio, luego el HTML
      const contenido = `<!-- 
Comando curl usado para obtener esta respuesta:
${curlCommand}
-->

${html}`

      // Guardar HTML con curl al principio
      await writeFile(filepath, contenido, 'utf-8')
      console.log(`üíæ [Milanuncios] HTML guardado en: ${filepath}`)
    } catch (error) {
      // No fallar si no se puede guardar el HTML
      console.warn(`‚ö†Ô∏è [Milanuncios] No se pudo guardar el HTML para debug:`, error)
    }
  }

  /**
   * Extrae el JSON de window.__INITIAL_CONTEXT_VALUE__ o window.__INITIAL_PROPS__ del HTML
   * Usa un enfoque que cuenta llaves balanceadas para extraer el JSON completo
   */
  private extraerJSONDelHTML(html: string): any {
    try {
      // Funci√≥n auxiliar para extraer JSON balanceado desde una posici√≥n
      const extraerJSONBalanceado = (texto: string, inicio: number): string | null => {
        let pos = inicio
        let nivel = 0
        let dentroString = false
        let escape = false
        let comilla = ''
        
        // Buscar la primera llave de apertura
        while (pos < texto.length && texto[pos] !== '{') {
          pos++
        }
        
        if (pos >= texto.length) return null
        
        const inicioJSON = pos
        nivel = 1
        pos++
        
        while (pos < texto.length && nivel > 0) {
          const char = texto[pos]
          
          if (escape) {
            escape = false
            pos++
            continue
          }
          
          if (char === '\\') {
            escape = true
            pos++
            continue
          }
          
          if (!dentroString) {
            if (char === '{') {
              nivel++
            } else if (char === '}') {
              nivel--
            } else if (char === '"' || char === "'") {
              dentroString = true
              comilla = char
            }
          } else {
            if (char === comilla) {
              dentroString = false
              comilla = ''
            }
          }
          
          pos++
        }
        
        if (nivel === 0) {
          return texto.substring(inicioJSON, pos)
        }
        
        return null
      }

      // Buscar window.__INITIAL_PROPS__ (usado en TODAS las p√°ginas, incluyendo la primera)
      // Usar regex para permitir espacios opcionales entre window. y __INITIAL_PROPS__
      const propsRegex = /window\s*\.\s*__INITIAL_PROPS__/i
      const propsMatch = html.match(propsRegex)
      
      if (propsMatch) {
        const propsParseIndex = propsMatch.index!
        console.log(`üîç [Milanuncios] Encontrado __INITIAL_PROPS__ en posici√≥n ${propsParseIndex}`)
        
        // Intentar con JSON.parse primero (formato: window.__INITIAL_PROPS__ = JSON.parse("..."))
        // Necesitamos capturar todo el contenido entre las comillas, incluso con saltos de l√≠nea
        // Buscar desde la posici√≥n encontrada
        const htmlDesdeProps = html.substring(propsParseIndex)
        
        // Buscar el inicio de JSON.parse(" o JSON.parse(' (permitir espacios)
        const parseRegex = /JSON\s*\.\s*parse\s*\(/i
        const parseMatch = htmlDesdeProps.match(parseRegex)
        
        if (parseMatch) {
          const parseStart = parseMatch.index!
          const parseEnd = parseMatch.index! + parseMatch[0].length
          
          // Buscar la comilla de apertura despu√©s de JSON.parse(
          let pos = parseEnd
          // Saltar espacios en blanco
          while (pos < htmlDesdeProps.length && /\s/.test(htmlDesdeProps[pos])) {
            pos++
          }
          
          if (pos >= htmlDesdeProps.length) {
            console.log(`‚ö†Ô∏è [Milanuncios] No se encontr√≥ comilla despu√©s de JSON.parse(`)
          } else {
            const comillaInicio = htmlDesdeProps[pos]
            if (comillaInicio !== '"' && comillaInicio !== "'") {
              console.log(`‚ö†Ô∏è [Milanuncios] Car√°cter inesperado despu√©s de JSON.parse(: "${comillaInicio}" (esperaba " o ')`)
            } else {
              const inicioContenido = pos + 1
              
              // Buscar la comilla de cierre balanceada (respetando escapes)
              let dentroString = true
              let escape = false
              let posActual = inicioContenido
              
              while (posActual < htmlDesdeProps.length && dentroString) {
                const char = htmlDesdeProps[posActual]
                
                if (escape) {
                  escape = false
                } else if (char === '\\') {
                  escape = true
                } else if (char === comillaInicio) {
                  dentroString = false
                  break
                }
                posActual++
              }
              
              if (!dentroString) {
                // Extraer el contenido escapado
                const escaped = htmlDesdeProps.substring(inicioContenido, posActual)
                console.log(`üìä [Milanuncios] JSON escapado extra√≠do: ${escaped.length} caracteres`)
                
                try {
                  // El contenido dentro de JSON.parse("...") est√° escapado como string de JavaScript
                  // Necesitamos desescaparlo correctamente antes de parsearlo como JSON
                  // El string escapado puede contener: \", \\, \n, \r, \t, \uXXXX, etc.
                  
                  // Funci√≥n para desescapar un string de JavaScript de forma segura
                  const desescaparStringJS = (str: string): string => {
                    let result = ''
                    let i = 0
                    while (i < str.length) {
                      if (str[i] === '\\' && i + 1 < str.length) {
                        const next = str[i + 1]
                        switch (next) {
                          case '"':
                            result += '"'
                            i += 2
                            break
                          case '\\':
                            result += '\\'
                            i += 2
                            break
                          case 'n':
                            result += '\n'
                            i += 2
                            break
                          case 'r':
                            result += '\r'
                            i += 2
                            break
                          case 't':
                            result += '\t'
                            i += 2
                            break
                          case 'u':
                            // Unicode escape: \uXXXX
                            if (i + 5 < str.length) {
                              const hex = str.substring(i + 2, i + 6)
                              try {
                                result += String.fromCharCode(parseInt(hex, 16))
                                i += 6
                              } catch {
                                result += '\\u' + hex
                                i += 6
                              }
                            } else {
                              result += str[i]
                              i++
                            }
                            break
                          default:
                            result += str[i]
                            i++
                        }
                      } else {
                        result += str[i]
                        i++
                      }
                    }
                    return result
                  }
                  
                  // Desescapar el string de JavaScript
                  const unescaped = desescaparStringJS(escaped)
                  
                  // Ahora parsear el JSON desescapado
                  const parsed = JSON.parse(unescaped)
                  console.log(`‚úÖ [Milanuncios] JSON extra√≠do correctamente desde __INITIAL_PROPS__ (JSON.parse)`)
                  return parsed
                } catch (parseError) {
                  console.error(`‚ùå [Milanuncios] Error parseando __INITIAL_PROPS__ (JSON.parse):`, parseError)
                  if (parseError instanceof Error) {
                    console.error(`‚ùå [Milanuncios] Error message: ${parseError.message}`)
                    // Mostrar d√≥nde fall√≥ el parseo
                    if (parseError.message.includes('position')) {
                      const match = parseError.message.match(/position (\d+)/)
                      if (match) {
                        const errorPos = parseInt(match[1])
                        const start = Math.max(0, errorPos - 50)
                        const end = Math.min(escaped.length, errorPos + 50)
                        console.error(`‚ùå [Milanuncios] Contexto del error (posici√≥n ${errorPos}): ...${escaped.substring(start, end)}...`)
                      }
                    }
                  }
                  // Mostrar fragmento del JSON escapado para debug
                  console.log(`üîç [Milanuncios] Fragmento del JSON escapado (primeros 500 chars): ${escaped.substring(0, 500)}...`)
                }
              } else {
                console.log(`‚ö†Ô∏è [Milanuncios] No se encontr√≥ comilla de cierre balanceada`)
              }
            }
          }
        }
        
        // Si no funciona con JSON.parse, intentar extraer directamente (formato: window.__INITIAL_PROPS__ = {...})
        const jsonStr = extraerJSONBalanceado(html, propsParseIndex)
        if (jsonStr) {
          try {
            const parsed = JSON.parse(jsonStr)
            console.log(`‚úÖ [Milanuncios] JSON extra√≠do correctamente desde __INITIAL_PROPS__ (directo)`)
            return parsed
          } catch (parseError) {
            console.error(`‚ùå [Milanuncios] Error parseando __INITIAL_PROPS__ (directo):`, parseError)
            if (parseError instanceof Error) {
              console.error(`‚ùå [Milanuncios] Error message: ${parseError.message}`)
            }
            console.log(`üîç [Milanuncios] Fragmento del JSON (primeros 500 chars): ${jsonStr.substring(0, 500)}...`)
          }
        } else {
          console.log(`üîç [Milanuncios] Encontrado __INITIAL_PROPS__ pero no se pudo extraer JSON balanceado`)
        }
      }

      // Debug: mostrar informaci√≥n si no se encontr√≥ nada
      if (!propsMatch) {
        console.log(`üîç [Milanuncios] No se encontr√≥ __INITIAL_PROPS__ en el HTML`)
        // Buscar cualquier referencia a window.__INITIAL para debug
        const anyInitial = html.match(/window\s*\.\s*__INITIAL[^\s=]*/gi)
        if (anyInitial) {
          console.log(`üîç [Milanuncios] Variables encontradas que empiezan con __INITIAL: ${anyInitial.join(', ')}`)
        }
      }

      return null
    } catch (error) {
      console.error(`‚ùå [Milanuncios] Error extrayendo JSON del HTML:`, error)
      if (error instanceof Error) {
        console.error(`‚ùå [Milanuncios] Error message: ${error.message}`)
        console.error(`‚ùå [Milanuncios] Error stack: ${error.stack?.substring(0, 300)}`)
      }
      return null
    }
  }

  /**
   * Construye la URL de b√∫squeda para la primera p√°gina
   */
  private construirURLPrimeraPagina(producto: string, lat: number, lon: number): string {
    const productoEncoded = encodeURIComponent(producto)
    return `https://www.milanuncios.com/anuncios/?s=${productoEncoded}&latitude=${lat}&longitude=${lon}&distance=300000&orden=relevance&fromSearch=1&fromSuggester=0&suggestionUsed=0&hitOrigin=listing&recentSearchShowed=0&recentSearchUsed=0`
  }

  /**
   * Construye la URL de b√∫squeda para p√°ginas siguientes
   */
  private construirURLPaginaSiguiente(producto: string, nextToken: string, pagina: number, lat: number, lon: number): string {
    const productoEncoded = encodeURIComponent(producto)
    return `https://www.milanuncios.com/anuncios/?fromSearch=1&fromSuggester=0&hitOrigin=listing&latitude=${lat}&longitude=${lon}&distance=300000&orden=relevance&recentSearchShowed=0&recentSearchUsed=0&s=${productoEncoded}&suggestionUsed=0&nextToken=${encodeURIComponent(nextToken)}&pagina=${pagina}`
  }

  /**
   * Extrae y mapea los anuncios desde el JSON de Milanuncios
   */
  private mapearAnuncios(data: any, producto: string): AnuncioRaw[] {
    const anuncios: AnuncioRaw[] = []

    try {
      // Extraer la lista de anuncios
      const ads = data?.adListPagination?.adList?.ads || []

      if (!Array.isArray(ads) || ads.length === 0) {
        console.log(`‚ö†Ô∏è [Milanuncios] No se encontraron anuncios en la respuesta`)
        return anuncios
      }

      console.log(`üìä [Milanuncios] Procesando ${ads.length} anuncios...`)

      for (const ad of ads) {
        try {
          // Mapear campos seg√∫n especificaciones
          const ciudad = ad?.city?.name || ad?.location?.city?.name || null
          const descripcion = ad?.description || null
          
          // Imagen: tomar el primer elemento y a√±adir https:// y ?rule=detail_640x480
          let imagen: string | null = null
          if (Array.isArray(ad?.images) && ad.images.length > 0) {
            const primeraImagen = ad.images[0]
            if (typeof primeraImagen === 'string') {
              // Si ya tiene https://, no a√±adirlo de nuevo
              if (primeraImagen.startsWith('http://') || primeraImagen.startsWith('https://')) {
                imagen = `${primeraImagen}?rule=detail_640x480`
              } else {
                imagen = `https://${primeraImagen}?rule=detail_640x480`
              }
            }
          }

          const fechaPublicacion = ad?.publishDate || null
          
          // URL: a√±adir https://www.milanuncios.com/ si no lo tiene
          let urlAnuncio = ad?.url || null
          if (urlAnuncio && !urlAnuncio.startsWith('http://') && !urlAnuncio.startsWith('https://')) {
            urlAnuncio = `https://www.milanuncios.com${urlAnuncio}`
          }

          const userId = ad?.userId?.toString() || null
          
          // is_shippable: true si existe shippingType, false si no
          const isShippable = ad?.shippingType ? true : false

          const titulo = ad?.title || null
          
          // Precio: extraer de price.cashPrice.value
          const precio = ad?.price?.cashPrice?.value || null

          // Estado: extraer de tags[].text (puede ser array)
          let estado: string | null = null
          if (Array.isArray(ad?.tags) && ad.tags.length > 0) {
            // Buscar el tag con type "estado del producto"
            const estadoTag = ad.tags.find((tag: any) => tag?.type === 'estado del producto')
            if (estadoTag?.text) {
              estado = estadoTag.text
            } else if (ad.tags[0]?.text) {
              // Si no hay tag de estado, tomar el primero
              estado = ad.tags[0].text
            }
          }

          // Mapear el estado de Milanuncios al estado interno
          estado = this.mapearEstadoMilanuncios(estado)

          // is_top_profile: usar isVipContent
          const isTopProfile = ad?.isVipContent || false

          // Validar que tenemos los campos m√≠nimos
          if (!titulo || precio === null) {
            console.warn(`‚ö†Ô∏è [Milanuncios] Anuncio sin t√≠tulo o precio, omitiendo:`, ad?.id)
            continue
          }

          // Convertir precio a n√∫mero
          const precioEur = typeof precio === 'number' ? precio : parseFloat(precio?.toString() || '0') || 0

          const anuncio: AnuncioRaw = {
            plataforma: 'milanuncios',
            titulo: titulo,
            precio: precioEur,
            precio_eur: precioEur,
            moneda_original: 'EUR',
            estado_declarado: estado || undefined,
            ciudad_o_zona: ciudad || undefined,
            url_anuncio: urlAnuncio || `https://www.milanuncios.com/anuncios/?s=${encodeURIComponent(producto)}`,
            fecha_publicacion: fechaPublicacion || undefined,
            descripcion: descripcion || undefined,
            id_anuncio: ad?.id?.toString() || undefined,
            product_image: imagen || null,
            is_shippable: isShippable,
            is_top_profile: isTopProfile,
            user_id: userId || null,
          }

          anuncios.push(anuncio)
        } catch (error) {
          console.error(`‚ùå [Milanuncios] Error procesando anuncio:`, error)
          continue
        }
      }

      console.log(`‚úÖ [Milanuncios] ${anuncios.length} anuncios mapeados correctamente`)
    } catch (error) {
      console.error(`‚ùå [Milanuncios] Error mapeando anuncios:`, error)
    }

    return anuncios
  }

  /**
   * Busca productos en Milanuncios
   */
  async buscar(inputs: ScrapingInputs): Promise<AnuncioRaw[]> {
    console.log(`\n${'‚ïê'.repeat(80)}`)
    console.log(`üï∑Ô∏è [Milanuncios] INICIANDO B√öSQUEDA EN MILANUNCIOS`)
    console.log(`${'‚ïê'.repeat(80)}`)
    console.log(`üìã [Milanuncios] Par√°metros de b√∫squeda:`)
    console.log(`   - Producto: "${inputs.producto_text}"`)
    console.log(`   - Ubicaci√≥n: "${inputs.ubicacion}"`)
    console.log(`   - Radio: ${inputs.radio_km}km`)
    console.log(`${'‚ïê'.repeat(80)}\n`)

    const anuncios: AnuncioRaw[] = []

    try {
      const producto = inputs.producto_text
      const maxPages = parseInt(process.env.MILANUNCIOS_MAX_PAGES || '10', 10)

      // Generar headers aleatorios para simular diferentes navegadores y sesiones
      // Esto ayuda a evitar la detecci√≥n de bots variando el fingerprint de cada petici√≥n
      const headers = this.generarHeadersAleatorios()
      console.log(`üîÄ [Milanuncios] Headers aleatorios generados para simular navegador diferente`)

      // Verificar si ScraperAPI est√° configurado
      console.log(`\nüîê [Milanuncios] Paso 1: Verificando configuraci√≥n de ScraperAPI...`)
      const scraperApiKey = process.env.SCRAPERAPI_KEY
      const useScraperAPI = !!scraperApiKey
      console.log(`   ${useScraperAPI ? '‚úÖ' : '‚ùå'} ScraperAPI: ${useScraperAPI ? 'CONFIGURADO' : 'NO CONFIGURADO'}`)
      if (useScraperAPI) {
        console.log(`   üîë API Key: ${scraperApiKey?.substring(0, 10)}...${scraperApiKey?.substring(scraperApiKey.length - 4)}`)
      }

      // Obtener coordenadas de la IP del usuario (si est√°n disponibles)
      console.log(`\n${'‚ïê'.repeat(80)}`)
      console.log(`üìç [Milanuncios] VERIFICANDO COORDENADAS DE IP`)
      console.log(`${'‚ïê'.repeat(80)}`)
      const coordenadasIP = inputs.coordenadas_ip || null
      const lat = coordenadasIP?.lat || 40.4260459
      const lon = coordenadasIP?.lon || -3.5651646
      
      if (coordenadasIP) {
        console.log(`‚úÖ [Milanuncios] Coordenadas de IP disponibles`)
        console.log(`üìç [Milanuncios] Latitud: ${lat}`)
        console.log(`üìç [Milanuncios] Longitud: ${lon}`)
        console.log(`üìç [Milanuncios] Origen: IP del usuario`)
      } else {
        console.log(`‚ö†Ô∏è [Milanuncios] No hay coordenadas de IP disponibles, usando coordenadas por defecto`)
        console.log(`üìç [Milanuncios] Latitud: ${lat} (Madrid por defecto)`)
        console.log(`üìç [Milanuncios] Longitud: ${lon} (Madrid por defecto)`)
        console.log(`üìç [Milanuncios] Origen: Coordenadas por defecto`)
      }
      console.log(`üìç [Milanuncios] Distancia: 300000 (300km)`)
      console.log(`${'‚ïê'.repeat(80)}\n`)

      // Construir URL de la primera p√°gina
      console.log(`\nüîó [Milanuncios] Paso 2: Construyendo URL de la primera p√°gina...`)
      const urlPrimeraPagina = this.construirURLPrimeraPagina(producto, lat, lon)
      console.log(`   üîó URL base: ${urlPrimeraPagina}`)
      console.log(`   üìä Par√°metros:`)
      console.log(`      - Producto: "${producto}" (encoded: "${encodeURIComponent(producto)}")`)
      console.log(`      - Latitud: ${lat}`)
      console.log(`      - Longitud: ${lon}`)
      console.log(`      - Distancia: 300000 (300km)`)

      // Construir URL final (a trav√©s de ScraperAPI si est√° configurado, o directo)
      console.log(`\nüîó [Milanuncios] Paso 3: Construyendo URL final y headers...`)
      let apiUrl: string
      let headersFinal: Record<string, string> = {}

      if (useScraperAPI) {
        // Usar ScraperAPI para evitar bloqueos
        // ScraperAPI es un servicio de proxy que ayuda a evitar bloqueos de IP desde Vercel
        // Milanuncios puede bloquear peticiones desde IPs de Vercel, por eso usamos un proxy
        const encodedUrl = encodeURIComponent(urlPrimeraPagina)
        apiUrl = `https://api.scraperapi.com?api_key=${scraperApiKey}&url=${encodedUrl}&country_code=es`
        console.log(`üîê [Milanuncios] Usando ScraperAPI para evitar bloqueos de IP`)
        console.log(`   ‚ÑπÔ∏è  Raz√≥n: Milanuncios puede bloquear peticiones desde IPs de Vercel`)
        console.log(`   ‚ÑπÔ∏è  ScraperAPI act√∫a como proxy para evitar estos bloqueos`)
        console.log(`üåç [Milanuncios] Pa√≠s configurado: ES (Espa√±a)`)
        // ScraperAPI maneja los headers autom√°ticamente, no necesitamos enviarlos
      } else {
        // Fallback a fetch directo (puede fallar en Vercel)
        apiUrl = urlPrimeraPagina
        console.log(`‚ö†Ô∏è [Milanuncios] SCRAPERAPI_KEY no configurada, usando fetch directo`)
        console.log(`   ‚ö†Ô∏è  ADVERTENCIA: Esto puede fallar en Vercel si Milanuncios bloquea las IPs`)
        console.log(`   ‚ö†Ô∏è  RAZ√ìN: Aunque el curl funciona en tu ordenador, el scraper puede fallar porque:`)
        console.log(`      - Las IPs de Vercel pueden estar bloqueadas por Milanuncios`)
        console.log(`      - Node.js tiene un TLS fingerprint diferente al de un navegador real`)
        console.log(`      - Falta de cookies/sesi√≥n que un navegador real tiene`)
        console.log(`      - Detecci√≥n avanzada de bots que identifica peticiones automatizadas`)
        console.log(`   üí° SOLUCI√ìN: Configura SCRAPERAPI_KEY en tus variables de entorno`)
        console.log(`      ScraperAPI act√∫a como proxy y simula un navegador real, evitando estos problemas`)
        
        // Headers para la petici√≥n
        headersFinal = headers
      }

      // Timeout: m√°s largo si usamos ScraperAPI (puede ser m√°s lento), m√°s corto si es directo
      const timeoutMs = useScraperAPI ? 15000 : 5000
      
      // Generar comando curl para logs
      let curlCommand = ''
      if (useScraperAPI) {
        // Curl para ScraperAPI
        curlCommand = `curl -X GET '${apiUrl}'`
      } else {
        // Curl directo a Milanuncios
        const headersForCurl = Object.entries(headersFinal)
          .map(([k, v]) => `  -H '${k}: ${v}'`)
          .join(' \\\n')
        curlCommand = `curl -X GET '${apiUrl}' \\\n${headersForCurl}`
      }
      
      console.log(`üåê [Milanuncios] Realizando petici√≥n a la primera p√°gina...`)
      console.log(`üîó [Milanuncios] URL: ${apiUrl.substring(0, 100)}...`)
      console.log(`‚è±Ô∏è [Milanuncios] Timeout configurado: ${timeoutMs}ms`)
      console.log(`\nüìã [Milanuncios] Comando curl equivalente:`)
      console.log(`‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`)
      console.log(curlCommand)
      console.log(`‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n`)
      const startTime = Date.now()
      
      // Verificar si estamos en Vercel
      const isVercelEnv = process.env.VERCEL === '1' || process.env.VERCEL === 'true'
      console.log(`üåç [Milanuncios] Entorno: ${isVercelEnv ? 'Vercel' : 'Local'}`)
      
      // Funci√≥n wrapper que garantiza que el timeout se ejecute
      const fetchWithTimeout = async (url: string, timeout: number, useProxy: boolean): Promise<Response> => {
        return new Promise(async (resolve, reject) => {
          // Crear AbortController
          const abortController = new AbortController()
          
          // Configurar timeout que SIEMPRE se ejecutar√°
          const timeoutId = setTimeout(() => {
            const elapsed = Date.now() - startTime
            console.error(`‚è∞ [Milanuncios] ‚ö†Ô∏è TIMEOUT TRIGGERED despu√©s de ${elapsed}ms (l√≠mite: ${timeout}ms)`)
            console.error(`‚è∞ [Milanuncios] Abortando fetch...`)
            abortController.abort()
            const errorMsg = useProxy
              ? `Timeout: La petici√≥n a trav√©s de ScraperAPI excedi√≥ ${timeout}ms`
              : `Timeout: La petici√≥n excedi√≥ ${timeout}ms - Posible bloqueo de Milanuncios desde Vercel`
            reject(new Error(errorMsg))
          }, timeout)
          
          // Log peri√≥dico para verificar que el c√≥digo sigue ejecut√°ndose
          const progressInterval = setInterval(() => {
            const elapsed = Date.now() - startTime
            if (elapsed < timeout + 1000) {
              const proxyInfo = useProxy ? ' (v√≠a ScraperAPI)' : ''
              console.log(`‚è≥ [Milanuncios] Heartbeat${proxyInfo} - Esperando respuesta... (${elapsed}ms / ${timeout}ms)`)
            } else {
              clearInterval(progressInterval)
            }
          }, 2000) // Log cada 2 segundos
          
          const proxyInfo = useProxy ? ' v√≠a ScraperAPI' : ' directo'
          if (useProxy) {
            console.log(`üì° [Milanuncios] Iniciando fetch${proxyInfo} con timeout de ${timeout}ms...`)
            console.log(`   ‚ÑπÔ∏è  ScraperAPI se usa para evitar bloqueos de IP desde Vercel`)
            console.log(`   ‚ÑπÔ∏è  Si no tienes SCRAPERAPI_KEY configurada, se usar√° fetch directo (puede fallar)`)
          } else {
            console.log(`üì° [Milanuncios] Iniciando fetch${proxyInfo} con timeout de ${timeout}ms...`)
            console.log(`   ‚ÑπÔ∏è  Fetch directo a Milanuncios (sin proxy)`)
          }
          
          try {
            // Preparar opciones de fetch
            const fetchOptions: RequestInit = {
              method: 'GET',
              signal: abortController.signal,
              redirect: 'follow', // Seguir redirecciones (comportamiento por defecto)
            }
            
            // Solo agregar headers si NO usamos ScraperAPI (ScraperAPI los maneja autom√°ticamente)
            if (!useProxy && Object.keys(headersFinal).length > 0) {
              fetchOptions.headers = headersFinal
              // Log de headers que se est√°n enviando para debug
              console.log(`üì§ [Milanuncios] Headers enviados:`)
              Object.entries(headersFinal).forEach(([key, value]) => {
                console.log(`   ${key}: ${value.substring(0, 80)}${value.length > 80 ? '...' : ''}`)
              })
            }
            
            // Ejecutar fetch
            const response = await fetch(url, fetchOptions)
            
            // Limpiar timeouts e intervals
            clearTimeout(timeoutId)
            clearInterval(progressInterval)
            
            const fetchTime = Date.now() - startTime
            console.log(`‚úÖ [Milanuncios] Respuesta recibida en ${fetchTime}ms`)
            console.log(`üìä [Milanuncios] Status: ${response.status} ${response.statusText}`)
            console.log(`üìä [Milanuncios] URL final (despu√©s de redirecciones): ${response.url}`)
            
            // Verificar si hay redirecci√≥n
            if (response.url !== url && !useProxy) {
              console.log(`‚ö†Ô∏è [Milanuncios] Hubo una redirecci√≥n: ${url} -> ${response.url}`)
            }
            
            // Verificar si ScraperAPI retorn√≥ un error
            if (useProxy && !response.ok) {
              try {
                const errorText = await response.text()
                console.error(`‚ùå [Milanuncios] ScraperAPI retorn√≥ error ${response.status}: ${errorText.substring(0, 200)}`)
                if (errorText.includes('account') || errorText.includes('quota') || errorText.includes('limit')) {
                  console.error(`‚ùå [Milanuncios] ‚ö†Ô∏è Posible problema con la cuenta de ScraperAPI (quota agotada o API key inv√°lida)`)
                  console.error(`‚ùå [Milanuncios] Verifica tu cuenta en https://www.scraperapi.com/dashboard`)
                }
              } catch (parseError) {
                // Si no se puede parsear el error, continuar
                console.error(`‚ùå [Milanuncios] Error HTTP ${response.status} de ScraperAPI`)
              }
            }
            
            resolve(response)
          } catch (error) {
            // Limpiar timeouts e intervals
            clearTimeout(timeoutId)
            clearInterval(progressInterval)
            
            const fetchTime = Date.now() - startTime
            
            if (error instanceof Error) {
              if (error.name === 'AbortError' || error.message.includes('aborted') || error.message.includes('Timeout')) {
                console.error(`‚ùå [Milanuncios] TIMEOUT despu√©s de ${fetchTime}ms: La petici√≥n fue abortada`)
                if (useProxy) {
                  console.error(`‚ùå [Milanuncios] ‚ö†Ô∏è ScraperAPI est√° tardando demasiado o hay un problema de conexi√≥n`)
                } else {
                  console.error(`‚ùå [Milanuncios] ‚ö†Ô∏è DIAGN√ìSTICO: Milanuncios probablemente est√° bloqueando peticiones desde Vercel`)
                  console.error(`‚ùå [Milanuncios] SOLUCI√ìN: Configura SCRAPERAPI_KEY para usar proxy`)
                }
              } else {
                console.error(`‚ùå [Milanuncios] Error de red despu√©s de ${fetchTime}ms:`, error.message)
                console.error(`‚ùå [Milanuncios] Error name: ${error.name}`)
                if ('cause' in error && error.cause) {
                  console.error(`‚ùå [Milanuncios] Error cause:`, error.cause)
                }
              }
            } else {
              console.error(`‚ùå [Milanuncios] Error no identificado despu√©s de ${fetchTime}ms:`, error)
            }
            reject(error)
          }
        })
      }
      
      let response: Response
      try {
        // Usar el wrapper con timeout garantizado
        response = await fetchWithTimeout(apiUrl, timeoutMs, useScraperAPI)
      } catch (error) {
        // Si falla, retornar array vac√≠o en lugar de lanzar error
        // Esto permite que el scraping contin√∫e con otras plataformas
        console.error(`‚ùå [Milanuncios] No se pudo obtener respuesta de Milanuncios`)
        console.error(`‚ö†Ô∏è [Milanuncios] Continuando sin resultados de Milanuncios...`)
        return anuncios // Retornar array vac√≠o para no bloquear el proceso
      }

      if (!response.ok) {
        console.warn(`‚ö†Ô∏è [Milanuncios] Error HTTP ${response.status}: ${response.statusText}`)
        // Mostrar headers de respuesta para debug
        console.log(`üîç [Milanuncios] Headers de respuesta:`)
        response.headers.forEach((value, key) => {
          console.log(`   ${key}: ${value}`)
        })
        return anuncios
      }

      console.log(`‚úÖ [Milanuncios] Parseando HTML de la primera p√°gina...`)
      const html = await response.text()
      
      // Guardar HTML para debug
      await this.guardarHTML(html, producto, 1, apiUrl, curlCommand)
      
      // Debug: verificar si la respuesta es realmente HTML o es una redirecci√≥n/error
      if (html.includes('Pardon Our Interruption') || html.includes('Cloudflare') || html.includes('challenge')) {
        console.warn(`‚ö†Ô∏è [Milanuncios] La respuesta parece ser una p√°gina de protecci√≥n anti-bot`)
        console.warn(`‚ö†Ô∏è [Milanuncios] Esto puede indicar que Milanuncios est√° bloqueando la petici√≥n`)
        console.warn(`üí° [Milanuncios] SOLUCI√ìN: Configura SCRAPERAPI_KEY para usar un proxy`)
      }
      
      // Debug: verificar tama√±o del HTML y buscar indicadores
      console.log(`üìä [Milanuncios] Tama√±o del HTML recibido: ${html.length} caracteres`)
      if (html.length < 1000) {
        console.warn(`‚ö†Ô∏è [Milanuncios] HTML muy peque√±o, puede ser una p√°gina de error o redirecci√≥n`)
        console.log(`üîç [Milanuncios] Primeros 500 caracteres del HTML: ${html.substring(0, 500)}`)
      }
      
      // Verificar si el HTML contiene el patr√≥n esperado
      const tieneProps = html.includes('window.__INITIAL_PROPS__')
      console.log(`üîç [Milanuncios] Contiene __INITIAL_PROPS__: ${tieneProps}`)
      
      // Extraer JSON del HTML
      const data = this.extraerJSONDelHTML(html)
      if (!data) {
        console.error(`‚ùå [Milanuncios] No se pudo extraer JSON del HTML`)
        // Si el HTML es muy peque√±o o parece un error, mostrar m√°s informaci√≥n
        if (html.length < 5000 || html.includes('error') || html.includes('Error') || html.includes('403') || html.includes('404')) {
          console.log(`üîç [Milanuncios] El HTML parece ser una p√°gina de error. Primeros 1000 caracteres:`)
          console.log(html.substring(0, 1000))
        }
        return anuncios
      }

      console.log(`‚úÖ [Milanuncios] JSON extra√≠do correctamente`)

      // Mapear anuncios de la primera p√°gina
      const anunciosPrimeraPagina = this.mapearAnuncios(data, producto)
      anuncios.push(...anunciosPrimeraPagina)

      // Obtener nextToken para paginaci√≥n
      let nextToken = data?.adListPagination?.pagination?.nextToken
      let paginaActual = 1

      // Paginaci√≥n: desde p√°gina 2 hasta maxPages
      while (nextToken && paginaActual < maxPages) {
        paginaActual++
        console.log(`\nüìÑ [Milanuncios] Obteniendo p√°gina ${paginaActual}/${maxPages}...`)

        // Verificaci√≥n de seguridad: si por alguna raz√≥n excedemos el l√≠mite, salir inmediatamente
        if (paginaActual > maxPages) {
          console.log(`üõë [Milanuncios] L√≠mite de p√°ginas excedido (${paginaActual} > ${maxPages}), deteniendo paginaci√≥n`)
          break
        }

        try {
          // Esperar 10 segundos antes de cada llamada para evitar rate limiting
          console.log(`‚è≥ [Milanuncios] Esperando 10 segundos antes de la p√°gina ${paginaActual} (rate limiting)...`)
          await new Promise(resolve => setTimeout(resolve, 10000))
          
          // Generar headers aleatorios nuevos para esta p√°gina (simular navegador/sesi√≥n diferente)
          const nextHeaders = this.generarHeadersAleatorios()
          console.log(`üîÄ [Milanuncios] Headers aleatorios generados para p√°gina ${paginaActual} (simular navegador diferente)`)
          
          // Construir URL para la siguiente p√°gina (usar las mismas coordenadas de IP)
          const urlPagina = this.construirURLPaginaSiguiente(producto, nextToken, paginaActual, lat, lon)
          
          let nextApiUrl = urlPagina
          if (useScraperAPI && scraperApiKey) {
            const encodedUrl = encodeURIComponent(urlPagina)
            nextApiUrl = `https://api.scraperapi.com?api_key=${scraperApiKey}&url=${encodedUrl}&country_code=es`
          }

          // Generar comando curl para esta p√°gina
          let nextCurlCommand = ''
          if (useScraperAPI) {
            nextCurlCommand = `curl -X GET '${nextApiUrl}'`
          } else {
            const headersForCurl = Object.entries(nextHeaders)
              .map(([k, v]) => `  -H '${k}: ${v}'`)
              .join(' \\\n')
            nextCurlCommand = `curl -X GET '${nextApiUrl}' \\\n${headersForCurl}`
          }

          console.log(`üîç [Milanuncios] Consultando p√°gina ${paginaActual}: ${urlPagina.substring(0, 100)}...`)
          console.log(`\nüìã [Milanuncios] Comando curl para p√°gina ${paginaActual}:`)
          console.log(`‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`)
          console.log(nextCurlCommand)
          console.log(`‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n`)

          // Timeout de 10 segundos para cada petici√≥n (aumentado para Vercel)
          const nextTimeoutMs = 10000
          const nextStartTime = Date.now()
          
          // Crear AbortController para poder cancelar el fetch si hay timeout
          const nextAbortController = new AbortController()
          let nextTimeoutId: NodeJS.Timeout | null = null
          
          // Preparar opciones de fetch para la siguiente p√°gina
          const nextFetchOptions: RequestInit = {
            method: 'GET',
            signal: nextAbortController.signal,
          }
          
          // Solo agregar headers si NO usamos ScraperAPI (usar los headers aleatorios generados)
          if (!useScraperAPI && Object.keys(nextHeaders).length > 0) {
            nextFetchOptions.headers = nextHeaders
          }
          
          // Configurar timeout que cancela el fetch
          nextTimeoutId = setTimeout(() => {
            const elapsed = Date.now() - nextStartTime
            console.error(`‚è∞ [Milanuncios] Timeout en p√°gina ${paginaActual} despu√©s de ${elapsed}ms (l√≠mite: ${nextTimeoutMs}ms)`)
            console.error(`üõë [Milanuncios] Cancelando fetch de p√°gina ${paginaActual}...`)
            nextAbortController.abort()
          }, nextTimeoutMs)
          
          let nextResponse: Response
          try {
            nextResponse = await fetch(nextApiUrl, nextFetchOptions)
            
            // Limpiar timeout si la petici√≥n fue exitosa
            if (nextTimeoutId) {
              clearTimeout(nextTimeoutId)
              nextTimeoutId = null
            }
            
            const nextFetchTime = Date.now() - nextStartTime
            console.log(`‚è±Ô∏è [Milanuncios] P√°gina ${paginaActual} recibida en ${nextFetchTime}ms`)
          } catch (nextError) {
            // Limpiar timeout si hay error
            if (nextTimeoutId) {
              clearTimeout(nextTimeoutId)
              nextTimeoutId = null
            }
            
            const nextFetchTime = Date.now() - nextStartTime
            if (nextError instanceof Error && (nextError.name === 'AbortError' || nextError.message.includes('Timeout') || nextError.message.includes('aborted'))) {
              console.error(`‚ùå [Milanuncios] Timeout en p√°gina ${paginaActual} despu√©s de ${nextFetchTime}ms`)
              console.error(`üõë [Milanuncios] Deteniendo paginaci√≥n debido al timeout`)
            } else {
              console.error(`‚ùå [Milanuncios] Error en p√°gina ${paginaActual} despu√©s de ${nextFetchTime}ms:`, nextError)
              console.error(`üõë [Milanuncios] Deteniendo paginaci√≥n debido al error`)
            }
            // Limpiar nextToken para evitar que el bucle contin√∫e
            nextToken = null
            throw nextError
          }
          
          if (!nextResponse.ok) {
            console.warn(`‚ö†Ô∏è [Milanuncios] Error HTTP ${nextResponse.status} en p√°gina ${paginaActual}: ${nextResponse.statusText}`)
            console.warn(`üõë [Milanuncios] Deteniendo paginaci√≥n debido al error HTTP`)
            // Limpiar nextToken para evitar que el bucle contin√∫e
            nextToken = null
            break // Salir del bucle si hay error
          }

          const nextHtml = await nextResponse.text()
          
          // Guardar HTML para debug
          await this.guardarHTML(nextHtml, producto, paginaActual, nextApiUrl, nextCurlCommand)
          
          const nextData = this.extraerJSONDelHTML(nextHtml)

          if (!nextData) {
            console.warn(`‚ö†Ô∏è [Milanuncios] No se pudo extraer JSON de la p√°gina ${paginaActual}`)
            break
          }

          // Mapear anuncios de esta p√°gina
          const anunciosPagina = this.mapearAnuncios(nextData, producto)
          console.log(`üìä [Milanuncios] P√°gina ${paginaActual}: ${anunciosPagina.length} anuncios`)
          anuncios.push(...anunciosPagina)
          console.log(`üìä [Milanuncios] Total acumulado: ${anuncios.length} anuncios`)

          // Obtener nextToken para la siguiente p√°gina
          nextToken = nextData?.adListPagination?.pagination?.nextToken

          if (!nextToken) {
            console.log(`‚úÖ [Milanuncios] No hay m√°s p√°ginas disponibles`)
            break
          }

          // Verificaci√≥n adicional: si llegamos al m√°ximo de p√°ginas, salir
          if (paginaActual >= maxPages) {
            console.log(`‚úÖ [Milanuncios] L√≠mite de p√°ginas alcanzado (${maxPages})`)
            nextToken = null // Limpiar para asegurar que el bucle termine
            break
          }
        } catch (error) {
          console.error(`‚ùå [Milanuncios] Error obteniendo p√°gina ${paginaActual}:`, error)
          if (error instanceof Error && error.name === 'AbortError') {
            console.error(`‚ùå [Milanuncios] Timeout en p√°gina ${paginaActual}`)
          }
          // IMPORTANTE: Limpiar nextToken para evitar bucle infinito
          nextToken = null
          console.log(`üõë [Milanuncios] Deteniendo paginaci√≥n debido al error`)
          break // Salir del bucle si hay error
        }
      }

      console.log(`\n‚úÖ [Milanuncios] Paginaci√≥n completada: ${paginaActual} p√°ginas consultadas, ${anuncios.length} anuncios totales`)

      console.log(`‚úÖ [Milanuncios] B√∫squeda completada: ${anuncios.length} anuncios procesados`)
    } catch (error) {
      console.error(`‚ùå [Milanuncios] Error durante el scraping:`, error)
      if (error instanceof Error) {
        console.error(`‚ùå [Milanuncios] Error name: ${error.name}`)
        console.error(`‚ùå [Milanuncios] Error message: ${error.message}`)
      }
    }

    return anuncios
  }

  /**
   * Obtiene el detalle de un anuncio individual
   * NOTA: Milanuncios ya proporciona toda la informaci√≥n en el listado, no necesita obtener detalles
   */
  async obtenerDetalleAnuncio(url: string, numeroAnuncio?: number, totalAnuncios?: number): Promise<Partial<AnuncioRaw> | null> {
    // Milanuncios ya proporciona toda la informaci√≥n en el listado
    // No necesitamos hacer scraping adicional del detalle
    return null
  }
}
